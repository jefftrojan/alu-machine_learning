{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA_Bot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Xlqqhfb50kDUHlZ2cqzUX0ZmxZa9dR9q",
      "authorship_tag": "ABX9TyPqaqs4ulYaBlKL9EwkrgB/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d49c72093cd0451bb0838b4b9d975567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd0792b35a38466dbb7a1f19c63b6c4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_596317a6c6d944f39b19a4c4bfbc7a6a",
              "IPY_MODEL_c6016f50bf784408a89e0476799b5f45"
            ]
          }
        },
        "fd0792b35a38466dbb7a1f19c63b6c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "596317a6c6d944f39b19a4c4bfbc7a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_419dca8348ee4ce18372067f525cdccb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c99376c916f4901a8c30060258214c8"
          }
        },
        "c6016f50bf784408a89e0476799b5f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_639297136f41407895e75fe4155e7432",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:05&lt;00:00, 43.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86cb60b364ac41ee8aefdc434254b646"
          }
        },
        "419dca8348ee4ce18372067f525cdccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c99376c916f4901a8c30060258214c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "639297136f41407895e75fe4155e7432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86cb60b364ac41ee8aefdc434254b646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "982cd4a89ac044889b6ee262c3a52df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9709e82d2d364f2d9315a995ee5790a2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b28892a14c7c4ff7a655d407631a90bc",
              "IPY_MODEL_b31bafee886f4e6c99ddce71a1551cc3"
            ]
          }
        },
        "9709e82d2d364f2d9315a995ee5790a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b28892a14c7c4ff7a655d407631a90bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68f16aa4071b4a2eb85c5aea5491cde1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_327118069f6a4ba8b6064e19a7f246e1"
          }
        },
        "b31bafee886f4e6c99ddce71a1551cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce444b4a1a134f2ea2227dc04c82b78e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:01&lt;00:00, 18.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f0e4cade0f24e1fabb2c9eb7f3cc3a2"
          }
        },
        "68f16aa4071b4a2eb85c5aea5491cde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "327118069f6a4ba8b6064e19a7f246e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce444b4a1a134f2ea2227dc04c82b78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f0e4cade0f24e1fabb2c9eb7f3cc3a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "216b1df56ae24dbbb4f6a31c612273a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0645f7479ad4665b91eb97f6f1342ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b40ae82207d47f69cf78898d4ea3fc7",
              "IPY_MODEL_456331fa4a1646afb64b3c5e72142d8d"
            ]
          }
        },
        "d0645f7479ad4665b91eb97f6f1342ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b40ae82207d47f69cf78898d4ea3fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5102d03ed9f946fbb2d38adcaa8ec211",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_965d6f5fa4844e51901c45b4822028f0"
          }
        },
        "456331fa4a1646afb64b3c5e72142d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d93641d7ef5d49a09967762a0b7cb838",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 818kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f7d57fc5c754a179a36c012ca717b87"
          }
        },
        "5102d03ed9f946fbb2d38adcaa8ec211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "965d6f5fa4844e51901c45b4822028f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d93641d7ef5d49a09967762a0b7cb838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f7d57fc5c754a179a36c012ca717b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmerchan/holbertonschool-machine_learning/blob/main/QA_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3TKw87CSJJy",
        "outputId": "152bbd36-faf3-4b19-9e45-87a6aaeb12ca"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install tensorflow-hub\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (57.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (1.15.0)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 4.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 36.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIAqbEhDJOjO",
        "outputId": "237ff986-2dd8-44e9-ebb1-23629b7dbd9e"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "def question_answer(question, reference):\n",
        "    \"\"\"                                                                                                                 \n",
        "    Finds a snippet of text within a reference document to answer a question                                            \n",
        "                                                                                                                        \n",
        "    parameters:                                                                                                         \n",
        "        question [string]:                                                                                              \n",
        "            contains the question to answer                                                                             \n",
        "        reference [string]:                                                                                             \n",
        "            contains the reference document from which to find the answer                                               \n",
        "                                                                                                                        \n",
        "    returns:                                                                                                            \n",
        "        [string]:                                                                                                       \n",
        "            contains the answer                                                                                         \n",
        "        or None if no answer is found                                                                                   \n",
        "    \"\"\"\n",
        "    tokenizer = BertTokenizer.from_pretrained(\n",
        "        'bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "    model = hub.load(\"https://tfhub.dev/see--/bert-uncased-tf2-qa/1\")\n",
        "\n",
        "    quest_tokens = tokenizer.tokenize(question)\n",
        "    refer_tokens = tokenizer.tokenize(reference)\n",
        "\n",
        "    tokens = ['[CLS]'] + quest_tokens + ['[SEP]'] + refer_tokens + ['[SEP]']\n",
        "\n",
        "    input_word_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_mask = [1] * len(input_word_ids)\n",
        "    input_type_ids = [0] * (\n",
        "        1 + len(quest_tokens) + 1) + [1] * (len(refer_tokens) + 1)\n",
        "\n",
        "    input_word_ids, input_mask, input_type_ids = map(\n",
        "        lambda t: tf.expand_dims(\n",
        "            tf.convert_to_tensor(t, dtype=tf.int32), 0),\n",
        "        (input_word_ids, input_mask, input_type_ids))\n",
        "\n",
        "    outputs = model([input_word_ids, input_mask, input_type_ids])\n",
        "\n",
        "    short_start = tf.argmax(outputs[0][0][1:]) + 1\n",
        "    short_end = tf.argmax(outputs[1][0][1:]) + 1\n",
        "    answer_tokens = tokens[short_start: short_end + 1]\n",
        "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "\n",
        "\n",
        "    if answer is None or answer is \"\" or question in answer:\n",
        "      return None\n",
        "\n",
        "    return answer\n",
        "\n",
        "with open('drive/MyDrive/ZendeskArticles/PeerLearningDays.md') as f:\n",
        "    reference = f.read()\n",
        "\n",
        "print(question_answer('jherouhfuoernfnerjnfrn?', reference))\n",
        "print(question_answer('When are PLDs?', reference))\n",
        "print(question_answer('What is a potato?', reference))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jherouhfuoernfnerjnfrn ?\n",
            "on - site days from 9 : 00 am to 3 : 00 pm\n",
            "what is a potato ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSMLKxTzZWn2",
        "outputId": "75677450-3dd7-4092-e479-91b4ff4fb54b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "def answer_loop(reference):\n",
        "    \"\"\"                                                                                                                 \n",
        "    Answers questions from a reference text on loop (based on 1-loop.py)                                                \n",
        "                                                                                                                        \n",
        "    parameters:                                                                                                         \n",
        "        reference [string]:                                                                                             \n",
        "            the reference document from which to find the answer                                                        \n",
        "    \"\"\"\n",
        "    while (1):\n",
        "        user_input = input(\"Q: \")\n",
        "        user_input = user_input.lower()\n",
        "        if user_input == 'exit' or user_input == 'quit' \\\n",
        "           or user_input == 'goodbye' or user_input == 'bye':\n",
        "            print(\"A: Goodbye\")\n",
        "            break\n",
        "        answer = question_answer(user_input, reference)\n",
        "        if answer is None:\n",
        "            print(\"A: Sorry, I do not understand your question.\")\n",
        "        else:\n",
        "            print(\"A: \", answer)\n",
        "\n",
        "\n",
        "def question_answer(question, reference):\n",
        "    \"\"\"                                                                                                                 \n",
        "    Finds a snippet of text within a reference document to answer a question                                            \n",
        "                                                                                                                        \n",
        "    parameters:                                                                                                         \n",
        "        question [string]:                                                                                              \n",
        "            contains the question to answer                                                                             \n",
        "        reference [string]:                                                                                             \n",
        "            contains the reference document from which to find the answer                                               \n",
        "                                                                                                                        \n",
        "    returns:                                                                                                            \n",
        "        [string]:                                                                                                       \n",
        "            contains the answer                                                                                         \n",
        "        or None if no answer is found                                                                                   \n",
        "    \"\"\"\n",
        "    tokenizer = BertTokenizer.from_pretrained(\n",
        "        'bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "    model = hub.load(\"https://tfhub.dev/see--/bert-uncased-tf2-qa/1\")\n",
        "\n",
        "    quest_tokens = tokenizer.tokenize(question)\n",
        "    refer_tokens = tokenizer.tokenize(reference)\n",
        "\n",
        "    tokens = ['[CLS]'] + quest_tokens + ['[SEP]'] + refer_tokens + ['[SEP]']\n",
        "\n",
        "    input_word_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_mask = [1] * len(input_word_ids)\n",
        "    input_type_ids = [0] * (\n",
        "        1 + len(quest_tokens) + 1) + [1] * (len(refer_tokens) + 1)\n",
        "\n",
        "    input_word_ids, input_mask, input_type_ids = map(\n",
        "        lambda t: tf.expand_dims(\n",
        "            tf.convert_to_tensor(t, dtype=tf.int32), 0),\n",
        "        (input_word_ids, input_mask, input_type_ids))\n",
        "\n",
        "    outputs = model([input_word_ids, input_mask, input_type_ids])\n",
        "\n",
        "    short_start = tf.argmax(outputs[0][0][1:]) + 1\n",
        "    short_end = tf.argmax(outputs[1][0][1:]) + 1\n",
        "    answer_tokens = tokens[short_start: short_end + 1]\n",
        "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "\n",
        "    if answer is None or answer is \"\" or question in answer:\n",
        "        return None\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "with open('drive/MyDrive/ZendeskArticles/PeerLearningDays.md') as f:\n",
        "    reference = f.read()\n",
        "\n",
        "answer_loop(reference)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q: When are PLDs?\n",
            "A:  on - site days from 9 : 00 am to 3 : 00 pm\n",
            "Q: What are Mock Interviews?\n",
            "A: Sorry, I do not understand your question.\n",
            "Q: What does PLD stand for?\n",
            "A:  peer learning days\n",
            "Q: bye\n",
            "A: Goodbye\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OQreuLDgilh",
        "outputId": "886aeec0-29f6-4415-a5e7-79793f56f4fa"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "def semantic_search(corpus_path, sentence):\n",
        "    \"\"\"                                                                                                                 \n",
        "    Performs semantic search on a corpus of documents                                                                   \n",
        "                                                                                                                        \n",
        "    parameters:                                                                                                         \n",
        "        corpus_path [string]:                                                                                           \n",
        "            the path to the corpus of reference documents on which                                                      \n",
        "                to perform semantic search                                                                              \n",
        "        sentence [string]:                                                                                              \n",
        "            the sentence from which to perform semantic search                                                          \n",
        "                                                                                                                        \n",
        "    returns:                                                                                                            \n",
        "        [string]:                                                                                                       \n",
        "            the reference text of the document most similar to given sentence                                           \n",
        "    \"\"\"\n",
        "    documents = [sentence]\n",
        "\n",
        "    for filename in os.listdir(corpus_path):\n",
        "        if filename.endswith(\".md\") is False:\n",
        "            continue\n",
        "        with open(corpus_path + \"/\" + filename, \"r\", encoding=\"utf-8\") as f:\n",
        "            documents.append(f.read())\n",
        "\n",
        "    model = hub.load(\n",
        "        \"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
        "\n",
        "    embeddings = model(documents)\n",
        "\n",
        "    correlation = np.inner(embeddings, embeddings)\n",
        "\n",
        "    closest = np.argmax(correlation[0, 1:])\n",
        "\n",
        "    similar = documents[closest + 1]\n",
        "\n",
        "    return similar\n",
        "\n",
        "print(semantic_search('drive/MyDrive/ZendeskArticles', 'When are PLDs?'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/5'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder-large/5, Total size: 577.10MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/5'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PLD Overview\n",
            "Peer Learning Days (PLDs) are a time for you and your peers to ensure that each of you understands the concepts you've encountered in your projects, as well as a time for everyone to collectively grow in technical, professional, and soft skills. During PLD, you will collaboratively review prior projects with a group of cohort peers.\n",
            "PLD Basics\n",
            "PLDs are mandatory on-site days from 9:00 AM to 3:00 PM. If you cannot be present or on time, you must use a PTO. \n",
            "No laptops, tablets, or screens are allowed until all tasks have been whiteboarded and understood by the entirety of your group. This time is for whiteboarding, dialogue, and active peer collaboration. After this, you may return to computers with each other to pair or group program. \n",
            "Peer Learning Days are not about sharing solutions. This doesn't empower peers with the ability to solve problems themselves! Peer learning is when you share your thought process, whether through conversation, whiteboarding, debugging, or live coding. \n",
            "When a peer has a question, rather than offering the solution, ask the following:\n",
            "\"How did you come to that conclusion?\"\n",
            "\"What have you tried?\"\n",
            "\"Did the man page give you a lead?\"\n",
            "\"Did you think about this concept?\"\n",
            "Modeling this form of thinking for one another is invaluable and will strengthen your entire cohort.\n",
            "Your ability to articulate your knowledge is a crucial skill and will be required to succeed during technical interviews and through your career. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581,
          "referenced_widgets": [
            "d49c72093cd0451bb0838b4b9d975567",
            "fd0792b35a38466dbb7a1f19c63b6c4b",
            "596317a6c6d944f39b19a4c4bfbc7a6a",
            "c6016f50bf784408a89e0476799b5f45",
            "419dca8348ee4ce18372067f525cdccb",
            "9c99376c916f4901a8c30060258214c8",
            "639297136f41407895e75fe4155e7432",
            "86cb60b364ac41ee8aefdc434254b646",
            "982cd4a89ac044889b6ee262c3a52df7",
            "9709e82d2d364f2d9315a995ee5790a2",
            "b28892a14c7c4ff7a655d407631a90bc",
            "b31bafee886f4e6c99ddce71a1551cc3",
            "68f16aa4071b4a2eb85c5aea5491cde1",
            "327118069f6a4ba8b6064e19a7f246e1",
            "ce444b4a1a134f2ea2227dc04c82b78e",
            "0f0e4cade0f24e1fabb2c9eb7f3cc3a2",
            "216b1df56ae24dbbb4f6a31c612273a2",
            "d0645f7479ad4665b91eb97f6f1342ea",
            "5b40ae82207d47f69cf78898d4ea3fc7",
            "456331fa4a1646afb64b3c5e72142d8d",
            "5102d03ed9f946fbb2d38adcaa8ec211",
            "965d6f5fa4844e51901c45b4822028f0",
            "d93641d7ef5d49a09967762a0b7cb838",
            "8f7d57fc5c754a179a36c012ca717b87"
          ]
        },
        "id": "Rlf9SjokUUN2",
        "outputId": "ad8955a2-c845-4ed4-ecf0-e9aa2eb5769f"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "def question_answer(corpus_path):\n",
        "    \"\"\"                                                                                        \n",
        "    Answers questions from multiple reference texts                                            \n",
        "                                                                                               \n",
        "    parameters:                                                                                \n",
        "        corpus_path [string]:                                                                  \n",
        "            the path to the corpus of reference documents                                      \n",
        "    \"\"\"\n",
        "    while (1):\n",
        "        user_input = input(\"Q: \")\n",
        "        user_input = user_input.lower()\n",
        "        if user_input == 'exit' or user_input == 'quit' \\\n",
        "           or user_input == 'goodbye' or user_input == 'bye':\n",
        "            print(\"A: Goodbye\")\n",
        "            break\n",
        "        reference = semantic_search(corpus_path, user_input)\n",
        "        answer = specific_question_answer(user_input, reference)\n",
        "        if answer is None:\n",
        "            print(\"A: Sorry, I do not understand your question.\")\n",
        "        else:\n",
        "            print(\"A: \", answer)\n",
        "\n",
        "def semantic_search(corpus_path, sentence):\n",
        "    \"\"\"                                                                                        \n",
        "    Performs semantic search on a corpus of documents                                          \n",
        "                                                                                               \n",
        "    parameters:                                                                                \n",
        "        corpus_path [string]:                                                                  \n",
        "            the path to the corpus of reference documents on which                             \n",
        "                to perform semantic search                                                     \n",
        "        sentence [string]:                                                                     \n",
        "            the sentence from which to perform semantic search                                 \n",
        "                                                                                               \n",
        "    returns:                                                                                   \n",
        "        [string]:                                                                              \n",
        "            the reference text of the document most similar to given sentence                  \n",
        "    \"\"\"\n",
        "    documents = [sentence]\n",
        "\n",
        "    for filename in os.listdir(corpus_path):\n",
        "        if filename.endswith(\".md\") is False:\n",
        "            continue\n",
        "        with open(corpus_path + \"/\" + filename, \"r\", encoding=\"utf-8\") as f:\n",
        "            documents.append(f.read())\n",
        "\n",
        "    model = hub.load(\n",
        "        \"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
        "\n",
        "    embeddings = model(documents)\n",
        "    correlation = np.inner(embeddings, embeddings)\n",
        "    closest = np.argmax(correlation[0, 1:])\n",
        "    similar = documents[closest + 1]\n",
        "\n",
        "    return similar\n",
        "\n",
        "def specific_question_answer(question, reference):\n",
        "    \"\"\"                                                                                        \n",
        "    Finds a snippet of text within a reference document to answer a question                   \n",
        "                                                                                               \n",
        "    parameters:                                                                                \n",
        "        question [string]:                                                                     \n",
        "            contains the question to answer                                                    \n",
        "        reference [string]:                                                                    \n",
        "            contains the reference document from which to find the answer                      \n",
        "                                                                                               \n",
        "    returns:                                                                                   \n",
        "        [string]:                                                                              \n",
        "            contains the answer                                                                \n",
        "        or None if no answer is found                                                          \n",
        "    \"\"\"\n",
        "    tokenizer = BertTokenizer.from_pretrained(\n",
        "        'bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "    model = hub.load(\"https://tfhub.dev/see--/bert-uncased-tf2-qa/1\")\n",
        "\n",
        "    quest_tokens = tokenizer.tokenize(question)\n",
        "    refer_tokens = tokenizer.tokenize(reference)\n",
        "\n",
        "    tokens = ['[CLS]'] + quest_tokens + ['[SEP]'] + refer_tokens + ['[SEP]']\n",
        "\n",
        "    input_word_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_mask = [1] * len(input_word_ids)\n",
        "    input_type_ids = [0] * (\n",
        "        1 + len(quest_tokens) + 1) + [1] * (len(refer_tokens) + 1)\n",
        "\n",
        "    input_word_ids, input_mask, input_type_ids = map(\n",
        "        lambda t: tf.expand_dims(\n",
        "            tf.convert_to_tensor(t, dtype=tf.int32), 0),\n",
        "        (input_word_ids, input_mask, input_type_ids))\n",
        "\n",
        "    outputs = model([input_word_ids, input_mask, input_type_ids])\n",
        "\n",
        "    short_start = tf.argmax(outputs[0][0][1:]) + 1\n",
        "    short_end = tf.argmax(outputs[1][0][1:]) + 1\n",
        "    answer_tokens = tokens[short_start: short_end + 1]\n",
        "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "                                                                                               \n",
        "    if answer is None or answer is \"\" or question in answer:                                   \n",
        "        return None                                                                            \n",
        "                                                                                               \n",
        "    return answer\n",
        "\n",
        "question_answer('drive/MyDrive/ZendeskArticles')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q: When are PLDs?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/5'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder-large/5, Total size: 577.10MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/5'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d49c72093cd0451bb0838b4b9d975567",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "982cd4a89ac044889b6ee262c3a52df7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "216b1df56ae24dbbb4f6a31c612273a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/see--/bert-uncased-tf2-qa/1'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Downloading https://tfhub.dev/see--/bert-uncased-tf2-qa/1: 544.01MB\n",
            "INFO:absl:Downloading https://tfhub.dev/see--/bert-uncased-tf2-qa/1: 1.14GB\n",
            "INFO:absl:Downloaded https://tfhub.dev/see--/bert-uncased-tf2-qa/1, Total size: 1.27GB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/see--/bert-uncased-tf2-qa/1'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A:  on - site days from 9 : 00 am to 3 : 00 pm\n",
            "Q: What are Mock Interviews?\n",
            "A:  help you train for technical interviews\n",
            "Q: What does PLD stand for?\n",
            "A:  peer learning days\n",
            "Q: What is potato?\n",
            "A:  virtual groups of about 8 students , automatically created , based on a short quiz on study / work habits\n",
            "Q: What is jkjhrjkhrhkh?\n",
            "A: Sorry, I do not understand your question.\n",
            "Q: What does the Chief Kitchen Officer do?\n",
            "A:  to make sure that the kitchen is maintained to a high standard\n",
            "Q: exit\n",
            "A: Goodbye\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}